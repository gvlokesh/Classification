{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text generation tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvlokesh/Classification/blob/master/Text_generation_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kPZNe-yDmDva",
        "colab_type": "code",
        "outputId": "4be36199-2415-4f4f-a38b-bafe065ecd1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "# Taming of the shrew.txt can be downloaded from http://www.gutenberg.org/cache/epub/2245/pg2245.txt\n",
        "filename = \"Taming of the shrew.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q0rggwLnnPAd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i=0\n",
        "c=None\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pFCvOx8wnS7d",
        "colab_type": "code",
        "outputId": "43de5829-e616-4257-aa58-e2a9ffb71c9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  134260\n",
            "Total Vocab:  65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e-HHFkT7sWGq",
        "colab_type": "code",
        "outputId": "9c0ab08b-8ea8-4cf4-d6f1-cdef2084ae66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "i=0\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  134160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b1v-GWg_wgXr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4On5XnIOw_nb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Phisv9Y5xD1r",
        "colab_type": "code",
        "outputId": "0d58afc1-ba09-415f-fa70-e3be9d5f8497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(np.shape(X),np.shape(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(134160, 100, 1) (134160, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tvxpo07CxL6c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BatchMaker():\n",
        "      def __init__(self):\n",
        "          \n",
        "          self.i = 0  \n",
        "          self.X_train=X\n",
        "          self.y_train=y\n",
        "                           \n",
        "      def next_batch(self, batch_size):\n",
        "        x = self.X_train[self.i:self.i+batch_size]\n",
        "        y = self.y_train[self.i:self.i+batch_size]\n",
        "        self.i = (self.i + batch_size) % (len(self.X_train))\n",
        "        return x, y "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iIdPesc6zPLt",
        "colab_type": "code",
        "outputId": "d5120387-a63b-4bdd-95ec-5bb2f21eeaec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "ch=BatchMaker()\n",
        "#for i in range(7000):\n",
        "       # batch = ch.next_batch(1000)\n",
        "        #print(batch[1])\n",
        "X1= ch.next_batch(15)       \n",
        "print((X1[0]).shape)\n",
        "print((X1[1]).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15, 100, 1)\n",
            "(15, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mds62uGNzRX0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#LSTM parameter setup\n",
        "n_steps=100\n",
        "n_inputs=1\n",
        "n_classes=64\n",
        "n_hidden_units=256\n",
        "l_r = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kDFJmHPB2N9A",
        "colab_type": "code",
        "outputId": "295e2c80-30c8-4255-be0c-a0da1e3eb5d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "#define placeholder for input\n",
        "x1 = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
        "y1 = tf.placeholder(tf.float32, [None, n_classes])\n",
        "\n",
        "print(x1)\n",
        "print(y1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder:0\", shape=(?, 100, 1), dtype=float32)\n",
            "Tensor(\"Placeholder_1:0\", shape=(?, 64), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "arA8wl747MUn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define w and b\n",
        "weights = {\n",
        "    'in': tf.Variable(tf.random_normal([n_inputs,n_hidden_units])),\n",
        "    'out': tf.Variable(tf.random_normal([n_hidden_units,n_classes]))\n",
        "}\n",
        "biases = {\n",
        "    'in': tf.Variable(tf.constant(0.1,shape=[n_hidden_units,])),\n",
        "    'out': tf.Variable(tf.constant(0.1,shape=[n_classes,]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wWecqGaq7MXn",
        "colab_type": "code",
        "outputId": "a9dbe6c2-8727-4f13-beaa-2f1aa1bdd8e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "X_in = tf.reshape(x1, [-1, n_inputs])\n",
        "print (\"Shape of X is\" ,X_in)\n",
        "X_in = tf.matmul(X_in, weights['in']) + biases['in']\n",
        "print (\"Shape of X_in is\" ,X_in)\n",
        "X_in = tf.reshape(X_in, [-1,n_steps, n_hidden_units])\n",
        "print (\"Shape of X_in  after reshape is\" ,X_in)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X is Tensor(\"Reshape:0\", shape=(?, 1), dtype=float32)\n",
            "Shape of X_in is Tensor(\"add:0\", shape=(?, 256), dtype=float32)\n",
            "Shape of X_in  after reshape is Tensor(\"Reshape_1:0\", shape=(?, 100, 256), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kur47Axy8Vor",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ###SIngle lstm\n",
        "# batch_size_T  = tf.shape(X_in)[0]\n",
        "\n",
        "# lstm_cell = tf.nn.rnn_cell.LSTMCell(n_hidden_units, forget_bias=1.0, state_is_tuple=True)\n",
        "\n",
        "# _init_state = lstm_cell.zero_state(batch_size_T ,  dtype=tf.float32)\n",
        "# outputs,states = tf.nn.dynamic_rnn(lstm_cell, X_in, initial_state=_init_state, time_major=False)\n",
        "\n",
        "# print (\"Shape of outputs  is\" ,outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pgFqk1Ubq9di",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#multi lstm\n",
        "\n",
        "n_layers = 4\n",
        "batch_size_T  = tf.shape(X_in)[0]\n",
        "\n",
        "cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(num_units=n_hidden_units)\n",
        "          for layer in range(n_layers)])\n",
        "\n",
        "# _init_state = lstm_cell.zero_state(batch_size_T ,  dtype=tf.float32)-------\n",
        "outputs,states = tf.nn.dynamic_rnn(cell, X_in, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ysRfvvMp_Xm1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "outputs1 = tf.unstack(tf.transpose(outputs, [1,0,2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9PoJG5vi_amA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results = tf.matmul(outputs1[-1], weights['out']) + biases['out']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1E66zg9u_bOo",
        "colab_type": "code",
        "outputId": "5c11bd35-48b4-4102-a2a1-ae9f3461202e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "pred=results\n",
        "print (pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"add_1:0\", shape=(?, 64), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V5-ZuzL9_tQi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y1))\n",
        "train_op = tf.train.AdamOptimizer(l_r).minimize(cost)\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(pred,1),tf.argmax(y1,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "32rcuP2q2W6u",
        "colab_type": "code",
        "outputId": "87844a2d-ec8f-41fb-a611-e00c535c0ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2581
        }
      },
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver()\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "ch=BatchMaker()\n",
        "for e in range(10):\n",
        "  for i in range(1400):\n",
        "          batch_x, batch_y = ch.next_batch(100)  \n",
        "          out=sess.run(train_op,feed_dict={x1: batch_x, y1: batch_y}) \n",
        "          if i % 100 == 0:\n",
        "              print(\"at epoch :\",e,\" accuracy at step :\",i,\"is \",sess.run(accuracy,feed_dict={x1: batch_x,y1: batch_y,}))\n",
        "              \n",
        "           \n",
        "saver.save(sess, \"./model\")           \n",
        "         "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "at epoch : 0  accuracy at step : 0 is  0.2\n",
            "at epoch : 0  accuracy at step : 100 is  0.31\n",
            "at epoch : 0  accuracy at step : 200 is  0.18\n",
            "at epoch : 0  accuracy at step : 300 is  0.14\n",
            "at epoch : 0  accuracy at step : 400 is  0.2\n",
            "at epoch : 0  accuracy at step : 500 is  0.2\n",
            "at epoch : 0  accuracy at step : 600 is  0.16\n",
            "at epoch : 0  accuracy at step : 700 is  0.21\n",
            "at epoch : 0  accuracy at step : 800 is  0.21\n",
            "at epoch : 0  accuracy at step : 900 is  0.24\n",
            "at epoch : 0  accuracy at step : 1000 is  0.23\n",
            "at epoch : 0  accuracy at step : 1100 is  0.22\n",
            "at epoch : 0  accuracy at step : 1200 is  0.28\n",
            "at epoch : 0  accuracy at step : 1300 is  0.29\n",
            "at epoch : 1  accuracy at step : 0 is  0.24\n",
            "at epoch : 1  accuracy at step : 100 is  0.21\n",
            "at epoch : 1  accuracy at step : 200 is  0.28\n",
            "at epoch : 1  accuracy at step : 300 is  0.24\n",
            "at epoch : 1  accuracy at step : 400 is  0.25\n",
            "at epoch : 1  accuracy at step : 500 is  0.29\n",
            "at epoch : 1  accuracy at step : 600 is  0.21\n",
            "at epoch : 1  accuracy at step : 700 is  0.26\n",
            "at epoch : 1  accuracy at step : 800 is  0.24\n",
            "at epoch : 1  accuracy at step : 900 is  0.25\n",
            "at epoch : 1  accuracy at step : 1000 is  0.37\n",
            "at epoch : 1  accuracy at step : 1100 is  0.35\n",
            "at epoch : 1  accuracy at step : 1200 is  0.34\n",
            "at epoch : 1  accuracy at step : 1300 is  0.21\n",
            "at epoch : 2  accuracy at step : 0 is  0.16\n",
            "at epoch : 2  accuracy at step : 100 is  0.24\n",
            "at epoch : 2  accuracy at step : 200 is  0.33\n",
            "at epoch : 2  accuracy at step : 300 is  0.25\n",
            "at epoch : 2  accuracy at step : 400 is  0.37\n",
            "at epoch : 2  accuracy at step : 500 is  0.32\n",
            "at epoch : 2  accuracy at step : 600 is  0.3\n",
            "at epoch : 2  accuracy at step : 700 is  0.22\n",
            "at epoch : 2  accuracy at step : 800 is  0.32\n",
            "at epoch : 2  accuracy at step : 900 is  0.4\n",
            "at epoch : 2  accuracy at step : 1000 is  0.36\n",
            "at epoch : 2  accuracy at step : 1100 is  0.36\n",
            "at epoch : 2  accuracy at step : 1200 is  0.22\n",
            "at epoch : 2  accuracy at step : 1300 is  0.25\n",
            "at epoch : 3  accuracy at step : 0 is  0.22\n",
            "at epoch : 3  accuracy at step : 100 is  0.32\n",
            "at epoch : 3  accuracy at step : 200 is  0.3\n",
            "at epoch : 3  accuracy at step : 300 is  0.44\n",
            "at epoch : 3  accuracy at step : 400 is  0.32\n",
            "at epoch : 3  accuracy at step : 500 is  0.34\n",
            "at epoch : 3  accuracy at step : 600 is  0.31\n",
            "at epoch : 3  accuracy at step : 700 is  0.36\n",
            "at epoch : 3  accuracy at step : 800 is  0.42\n",
            "at epoch : 3  accuracy at step : 900 is  0.36\n",
            "at epoch : 3  accuracy at step : 1000 is  0.48\n",
            "at epoch : 3  accuracy at step : 1100 is  0.44\n",
            "at epoch : 3  accuracy at step : 1200 is  0.36\n",
            "at epoch : 3  accuracy at step : 1300 is  0.29\n",
            "at epoch : 4  accuracy at step : 0 is  0.48\n",
            "at epoch : 4  accuracy at step : 100 is  0.44\n",
            "at epoch : 4  accuracy at step : 200 is  0.32\n",
            "at epoch : 4  accuracy at step : 300 is  0.5\n",
            "at epoch : 4  accuracy at step : 400 is  0.52\n",
            "at epoch : 4  accuracy at step : 500 is  0.45\n",
            "at epoch : 4  accuracy at step : 600 is  0.43\n",
            "at epoch : 4  accuracy at step : 700 is  0.38\n",
            "at epoch : 4  accuracy at step : 800 is  0.42\n",
            "at epoch : 4  accuracy at step : 900 is  0.57\n",
            "at epoch : 4  accuracy at step : 1000 is  0.61\n",
            "at epoch : 4  accuracy at step : 1100 is  0.45\n",
            "at epoch : 4  accuracy at step : 1200 is  0.51\n",
            "at epoch : 4  accuracy at step : 1300 is  0.41\n",
            "at epoch : 5  accuracy at step : 0 is  0.52\n",
            "at epoch : 5  accuracy at step : 100 is  0.55\n",
            "at epoch : 5  accuracy at step : 200 is  0.34\n",
            "at epoch : 5  accuracy at step : 300 is  0.5\n",
            "at epoch : 5  accuracy at step : 400 is  0.43\n",
            "at epoch : 5  accuracy at step : 500 is  0.5\n",
            "at epoch : 5  accuracy at step : 600 is  0.55\n",
            "at epoch : 5  accuracy at step : 700 is  0.62\n",
            "at epoch : 5  accuracy at step : 800 is  0.43\n",
            "at epoch : 5  accuracy at step : 900 is  0.47\n",
            "at epoch : 5  accuracy at step : 1000 is  0.54\n",
            "at epoch : 5  accuracy at step : 1100 is  0.36\n",
            "at epoch : 5  accuracy at step : 1200 is  0.49\n",
            "at epoch : 5  accuracy at step : 1300 is  0.52\n",
            "at epoch : 6  accuracy at step : 0 is  0.56\n",
            "at epoch : 6  accuracy at step : 100 is  0.44\n",
            "at epoch : 6  accuracy at step : 200 is  0.46\n",
            "at epoch : 6  accuracy at step : 300 is  0.6\n",
            "at epoch : 6  accuracy at step : 400 is  0.47\n",
            "at epoch : 6  accuracy at step : 500 is  0.61\n",
            "at epoch : 6  accuracy at step : 600 is  0.53\n",
            "at epoch : 6  accuracy at step : 700 is  0.58\n",
            "at epoch : 6  accuracy at step : 800 is  0.6\n",
            "at epoch : 6  accuracy at step : 900 is  0.69\n",
            "at epoch : 6  accuracy at step : 1000 is  0.74\n",
            "at epoch : 6  accuracy at step : 1100 is  0.5\n",
            "at epoch : 6  accuracy at step : 1200 is  0.49\n",
            "at epoch : 6  accuracy at step : 1300 is  0.5\n",
            "at epoch : 7  accuracy at step : 0 is  0.46\n",
            "at epoch : 7  accuracy at step : 100 is  0.57\n",
            "at epoch : 7  accuracy at step : 200 is  0.48\n",
            "at epoch : 7  accuracy at step : 300 is  0.6\n",
            "at epoch : 7  accuracy at step : 400 is  0.62\n",
            "at epoch : 7  accuracy at step : 500 is  0.61\n",
            "at epoch : 7  accuracy at step : 600 is  0.53\n",
            "at epoch : 7  accuracy at step : 700 is  0.65\n",
            "at epoch : 7  accuracy at step : 800 is  0.68\n",
            "at epoch : 7  accuracy at step : 900 is  0.55\n",
            "at epoch : 7  accuracy at step : 1000 is  0.69\n",
            "at epoch : 7  accuracy at step : 1100 is  0.51\n",
            "at epoch : 7  accuracy at step : 1200 is  0.72\n",
            "at epoch : 7  accuracy at step : 1300 is  0.48\n",
            "at epoch : 8  accuracy at step : 0 is  0.59\n",
            "at epoch : 8  accuracy at step : 100 is  0.59\n",
            "at epoch : 8  accuracy at step : 200 is  0.55\n",
            "at epoch : 8  accuracy at step : 300 is  0.62\n",
            "at epoch : 8  accuracy at step : 400 is  0.66\n",
            "at epoch : 8  accuracy at step : 500 is  0.51\n",
            "at epoch : 8  accuracy at step : 600 is  0.69\n",
            "at epoch : 8  accuracy at step : 700 is  0.57\n",
            "at epoch : 8  accuracy at step : 800 is  0.65\n",
            "at epoch : 8  accuracy at step : 900 is  0.44\n",
            "at epoch : 8  accuracy at step : 1000 is  0.61\n",
            "at epoch : 8  accuracy at step : 1100 is  0.48\n",
            "at epoch : 8  accuracy at step : 1200 is  0.61\n",
            "at epoch : 8  accuracy at step : 1300 is  0.66\n",
            "at epoch : 9  accuracy at step : 0 is  0.58\n",
            "at epoch : 9  accuracy at step : 100 is  0.61\n",
            "at epoch : 9  accuracy at step : 200 is  0.58\n",
            "at epoch : 9  accuracy at step : 300 is  0.63\n",
            "at epoch : 9  accuracy at step : 400 is  0.59\n",
            "at epoch : 9  accuracy at step : 500 is  0.69\n",
            "at epoch : 9  accuracy at step : 600 is  0.61\n",
            "at epoch : 9  accuracy at step : 700 is  0.73\n",
            "at epoch : 9  accuracy at step : 800 is  0.62\n",
            "at epoch : 9  accuracy at step : 900 is  0.57\n",
            "at epoch : 9  accuracy at step : 1000 is  0.61\n",
            "at epoch : 9  accuracy at step : 1100 is  0.64\n",
            "at epoch : 9  accuracy at step : 1200 is  0.71\n",
            "at epoch : 9  accuracy at step : 1300 is  0.57\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./model'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "MB2wxaK3Ff7Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Inference starts here**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "i_ybdvvT-aoZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Omfxzqsx3dY",
        "colab_type": "code",
        "outputId": "78d3737a-db23-4740-b6d4-f530bc4b96dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "print(start)\n",
        "pattern = dataX[start]\n",
        "len(pattern)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "id": "gcIxlgCFVLce",
        "colab_type": "code",
        "outputId": "3411476e-f871-49ac-8410-562bb9d43e21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  \n",
        "  saver.restore(sess, \"./model\")\n",
        "      \n",
        "    ## Now create a for loop that \n",
        "  for i in range(1000):\n",
        "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        x = x / float(n_vocab)   \n",
        "        y_pred = sess.run(pred, feed_dict={x1: x})\n",
        "        index = np.argmax(y_pred)\n",
        "        result = int_to_char[index]\n",
        "#         print(result)\n",
        "        sys.stdout.write(result)\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "  print (\"\\nDone.\"    )     \n",
        "\t      \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./model\n",
            "fe, and the manke of mine\n",
            "\n",
            "   pet. why that is not sister then the eldest:\n",
            "i will go with his to my selfe, and the manke of my selfe,\n",
            "and the may be seuenge and behauiour,\n",
            "and the is my selfe, and the manke of mine\n",
            "\n",
            "   pet. why that is not sister then the eldest:\n",
            "i will go with his to my selfe, and the manke of my selfe,\n",
            "and the may be seuenge and behauiour,\n",
            "and the is my selfe, and the manke of mine\n",
            "\n",
            "   pet. why that is not sister then the eldest:\n",
            "i will go with his to my selfe, and the manke of my selfe,\n",
            "and the may be seuenge and behauiour,\n",
            "and the is my selfe, and the manke of mine\n",
            "\n",
            "   pet. why that is not sister then the eldest:\n",
            "i will go with his to my selfe, and the manke of my selfe,\n",
            "and the may be seuenge and behauiour,\n",
            "and the is my selfe, and the manke of mine\n",
            "\n",
            "   pet. why that is not sister then the eldest:\n",
            "i will go with his to my selfe, and the manke of my selfe,\n",
            "and the may be seuenge and behauiour,\n",
            "and the is my selfe, and the manke of mine\n",
            "\n",
            "   pet. why that is not sist\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6f67kIX3brct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}